---
---

# Conferences

%%%%%%%%%%% 2023 %%%%%%%%%%%

@inproceedings{giordano2023Milani,
  bibtex_show={true},
  title={The Hera Milani CubeSat mission},
  author={C Giordano, F Topputo, F Ferrari, V Franzese, M Pugliatti, F Piccolo, A Rizza, T Kohout, F Dirri, A Longobardo, C Gisellu, E Palomba, M Cardi, F Perez-Lissi, P Martino, I Carnelli},
  booktitle={5th COSPAR Symposium, 2023},
  year={2023},
  month = {April},
  pdf={https://hdl.handle.net/11573/1672600},
  abstract = {}
}

%%%%%%%%%%% 2022 %%%%%%%%%%%

@inproceedings{pugliatti2022boulders,
  bibtex_show={true},
  title={Boulders identification on small bodies under varying illumination conditions},
  author={Mattia Pugliatti and Francesco Topputo},
  booktitle={Space Imaging Workshop},
  pages={1--12},
  year={2022},
  month = {October},
  pdf={https://arxiv.org/pdf/2210.16283.pdf},
  dataset = {https://zenodo.org/record/7107409#.ZF5GS-xBxQI},
  preview = {pugliatti2022boulders.png},
  abstract = {The capability to detect boulders on the surface of small bodies is beneficial for vision-based applications such as navigation and hazard detection during critical operations. This task is challenging due to the wide assortment of irregular shapes, the characteristics of the boulders population, and the rapid variability in the illumination conditions. The authors address this challenge by designing a multi-step training approach to develop a data-driven image processing pipeline to robustly detect and segment boulders scattered over the surface of a small body. Due to the limited availability of labeled image-mask pairs, the developed methodology is supported by two artificial environments designed in Blender specifically for this work. These are used to generate a large amount of synthetic image-label sets, which are made publicly available to the image processing community. The methodology presented addresses the challenges of varying illumination conditions, irregular shapes, fast training time, extensive exploration of the architecture design space, and domain gap between synthetic and real images from previously flown missions. The performance of the developed image processing pipeline is tested both on synthetic and real images, exhibiting good performances, and high generalization capabilities.}
}

@inproceedings{rizza2022hardware,
  bibtex_show={true},
  title={Hardware-In-the-loop Simulation Framework for CubeSats Proximity Operations: Application to the Milani Mission},
  author={Rizza, Antonio and Piccolo, Felice and Pugliatti, Mattia and Panicucci, Paolo and Topputo, Francesco},
  booktitle={73rd International Astronautical Congress (IAC 2022)},
  pages={1--15},
  year={2022},
  month = {October},
  pdf={https://re.public.polimi.it/bitstream/11311/1221311/1/RIZZA01-22.pdf},
  abstract = { Milani is a 6U CubeSat that will be released by Hera in proximity of the Didymos binary asteroid. The spacecraft will demonstrate autonomous Guidance Navigation and Control (GNC) capability for CubeSats in deep space, enhancing the scientific outcome of the mission. The Deep-space Astrodynamics Research and Technology (DART) Group at Politecnico di Milano is responsible for Milani Mission Analysis (MA), GNC and Image Processing (IP) design. Operations in proximity of minor bodies demand high levels of autonomy to achieve cost-effective, safe, and reliable solutions. The on-board software has a central role in these applications, thus it must be extensively tested and validated to satisfy mission requirements and to guarantee robustness to uncertainties. A robust and standardized methodology to design, validate, and test vision-based Attitude and Orbit Control Systems (AOCS) algorithms is fundamental to achieve fast prototyping while facing at the same time limited availability of resources and time. This paper presents a modular and flexible approach, developed at DART lab, to test GNC algorithms with camera- and processor-in-the-loop simulations. This framework is characterized by three elements: 1) a functional engineering simulator for six-degrees-of-freedom closed-loop analyses, 2) a vision-based navigation test-bench for camera-in-the-loop simulations, and 3) a single-board computer to test the algorithm in a representative computational environment. The first element is the modular CUBesat ORbit and GNC (CUBORG) tool, developed in MATLAB/Simulink. This contains a high-fidelity model of the environment suitable for simulating different operative scenarios, and a prototype of the spacecraft AOCS. Camera-in-the loop simulations are performed thanks to the in-house developed Tiny Versatile 3D Reality Simulation Environment (TinyV3RSE). This is composed of a high-resolution screen which displays synthetic images as they would be acquired from the probe during the mission, and stimulates, through a collimator, the camera mounted in the facility. The third element is a Raspberry Pi which is selected as external board to run processor-in-the-loop simulations. The proposed approach is tested on the Milani case simulating the GNC and IP subsystems in a real-hardware environment, doing a step forward towards the hardware-in-the-loop validation and verification of them.}
}

@inproceedings{pugliatti2022board,
  bibtex_show={true},
  title={On-board Small-Body Semantic Segmentation Based on Morphological Features with U-Net},
  author={Pugliatti, Mattia and Maestrini, Michele and Di Lizia, Pierluigi and Topputo, Francesco and others},
  booktitle={Advances in the Astronautical Sciences},
  volume={176},
  pages={603--622},
  year={2022},
  publisher={Univelt},
  pdf = {https://www.researchgate.net/publication/349140381_Onboard_Small-Body_semantic_segmentation_based_on_morphological_features_with_U-Net},
  preview = {pugliatti2022board.png},
  abstract = {Small-bodies such as asteroids and comets exhibit great variability in surface morphological features. These are often unknown beforehand but can be exploited for hazard avoidance during landing, autonomous planning of scientific observations, and for navigation purposes. The detection and classification of such features is a laborious task that requires extensive manual work done by experts in the field. This step renders online usage of images unfeasible for these applications. Such limitation could be overcome thanks to the recent advances in the field of neural networks, which allow to recognize features automatically from an acquired image. However, to train such networks, an annotated dataset needs to be generated with care by field experts, thus requiring once again extensive work and human-in-the-loop. In this work, a methodology that exploits an open-source rendering software, ray-tracing masking, and simple image processing techniques is illustrated, which allows to automatize the segmentation process and build up a robust database of labeled features (i.e. background, surface, craters, boulders, and the terminator region) for small-bodies. A procedural code is designed to generate images and their labels over 7 different small-body shapes for a total of $12,550$ images that are used to train a Convolutional Neural Network with a U-Net architecture in the task of semantic segmentation. The performances of the network are then analyzed in 4 different scenarios. First, the network is evaluated on a test set composed of $1,050$ new images belonging to bodies seen during training. Secondly, the network is evaluated on $3,000$ synthetic images from 2 models that have not been encountered in training. Afterward, one of these latter models is tested in a flyby trajectory scenario consisting of $56$ images. The results of the first three tests show state of the art performances and the capability of this method to generalize features across synthetic data. Finally, the network's performances are qualitatively assessed with a set of $59$ real images from previously flown missions, highlighting the current limits of this approach. These shortcomings suggest possible directions for future improvement, which are discussed in this work.},
  slides = {TBD}
}

@inproceedings{pugliatti2022navigation,
  bibtex_show={true},
  title={Navigation about irregular bodies through segmentation maps},
  author={Mattia Pugliatti and Francesco Topputo},
  booktitle={Advances in the Astronautical Sciences},
  volume={176},
  pages={1169--1187},
  year={2022},
  publisher={Univelt},
  pdf = {https://www.researchgate.net/publication/349140716_Navigation_about_irregular_bodies_through_segmentation_maps},
  slides = {TBD},
  preview = {pugliatti2022navigation.png},
  abstract = {Optical navigation about small-bodies can be performed at different scales and with different techniques during proximity operations. Traditional methods however are influenced by pixel intensity due to illumination conditions and often provide a navigation solution only when coupled with filtering techniques. In this work, a navigation method for small-body applications is presented that makes use of segmentation maps. By converting a grayscale image into its segmented equivalent the pixel content is highly reduced but at the same time its meaning is enriched since the pixel value is providing direct information on feature type and distribution across space. This is exploited in an autonomous navigation method in two steps. A Convolutional Neural Network is designed to generate a rough estimate of the position of a spacecraft in a small-body fixed reference frame, whose surrounding has been divided into 1176 classes. A Normalized Cross-Correlation technique is then applied to the reduced search space to generate a precise position estimate. The methodology proposed is trained and validated on a database of segmented synthetic maps of 49716 samples of Didymos and Hartley each, while a series of 5 scenarios are tested. The CNN is capable to predict the correct class with an accuracy of $75.94\%$ and $68.60\%$ respectively for Didymos and Hartley, while the overwhelming majority of the other cases are predicted just next to the correct classes. The CNN is robust to various illumination conditions, is capable to work outside the range of distances considered during training, performs well when predicted masks are used, and also selects independently the type of features to rely on for classification depending on the body. When coupled with NCC, a position estimate with a relative error below $5-8\%$ the range from the asteroid can be achieved.}
}

@inproceedings{pugliatti2022design,
  bibtex_show={true},
  title={Design of the on-board image processing of the Milani mission},
  author={ and others},
  booktitle={44th AAS Guidance, Navigation and Control Conference},
  pages={1--21},
  year={2022},
  pdf = {https://www.researchgate.net/publication/363539056_Design_of_the_On-Board_Image_Processing_of_the_Milani_Mission},
  slides = {TBD},
  preview = {pugliatti2022design.png},
  abstract = {Milani is a 6U CubeSat that will visit the Didymos binary system as part of the Hera mission. Its objectives are both scientific and technological: to study and characterize the asteroid environment, and to demonstrate the use of CubeSat technologies for interplanetary missions. The latter includes optical-based autonomous navigation algorithms in a close-proximity environment, which are enabled by robust image processing functions. In this work, for the first time, the design of the image processing of Milani is described in detail. Its algorithmic core is divided among two blocks: the blobs characterization and the observables extraction. The former one extracts low-level optical observables while distinguishing the primary from the secondary of the Didymos system. The latter processes the input of the previous block to generate higher-level observables such as the center of figure, the range, and the phase angle. These estimates are generated thanks to data-driven functions which are tuned on a global dataset representative of the geometric conditions which Milani would encounter during its mission. After a detailed description of its functionalities, the image processing is tested on two datasets representative of the nominal mission phases: the far range phase and the close range phase. After the characterization of the various algorithms, it is demonstrated that Milani’s image processing is capable of robustly generating a set of optical observables to be used on-board by the GNC and the rest of the CubeSat.}
}
}

%%%%%%%%%%% 2021 %%%%%%%%%%%

@inproceedings{pugliatti2021shape,
  bibtex_show={true},
  title={Small-body shape recognition with convolutional neural network and comparison with explicit features based method},
  author={Mattia Pugliatti and Francesco Topputo},
  booktitle={Advances in the astronautical sciences},
  year={2021},
  month = {August},
  volume = {175},
  pages = {2539--2258},
  publisher = {Univelt},
  pdf = {https://www.researchgate.net/publication/344042457_Small-Body_shape_recognition_with_Convolutional_Neural_Network_and_comparison_with_explicit_features_based_methods},
  preview = {pugliatti2021shape.png},
  abstract = {Small-bodies such as asteroids and comets exhibit a wide variety of shapes and surface characteristics that are often unknown beforehand. Because of that, traditional exploration approaches do not make use of shape information on-board the spacecraft. This work would like to propose an approach based on Convolutional Neural Networks (CNN) to provide such type of information for on-board image processing and compare it with three more traditional approaches based on explicit image features such as Hu invariant moments, Fourier descriptors and polar outlines. A group of 8 different small-body shapes is chosen as archetype set and a database of images is generated to train these 4 techniques in the classification task. Their performances are then analyzed in three different scenarios. First, they are analyzed on the test set split from the database. In the second one the CNN is used to classify the shape of new objects that are not part of the archetype set. Lastly, all techniques are used under varying illumination conditions on some models from the archetype set. The CNN classifier outperforms the other methods, reaching an accuracy of 98.52%, meaningful classification on new models and a robust behaviour under varying illumination conditions. The latter property can be used for efficient training of the CNN with a smaller database. Given the promising results, the CNN classifier is proposed for onboard implementation to provide shape information. Other important results of this work are the identification of an irregularity index for small-bodies and the definition of a shape profile as a fingerprint of the 3D object under varying perspective.},
  slides = {TBD}
}

%%%%%%%%%%% 2020 %%%%%%%%%%%


%%%%%%%%%%% 2016 %%%%%%%%%%%

