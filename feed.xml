<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://mattiapugliatti.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://mattiapugliatti.github.io/" rel="alternate" type="text/html" hreflang="en" /><updated>2023-06-04T08:51:32+00:00</updated><id>https://mattiapugliatti.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
</subtitle><entry><title type="html">The “Milani IP” Dataset</title><link href="https://mattiapugliatti.github.io/blog/2023/milani/" rel="alternate" type="text/html" title="The “Milani IP” Dataset" /><published>2023-05-29T10:00:00+00:00</published><updated>2023-05-29T10:00:00+00:00</updated><id>https://mattiapugliatti.github.io/blog/2023/milani</id><content type="html" xml:base="https://mattiapugliatti.github.io/blog/2023/milani/"><![CDATA[<h2 id="what-is-the-milani-ip-dataset">What is the “Milani IP” Dataset?</h2>

<p>This dataset contains data used in the work “The image processing of Milani challenges after DART impact”, by Mattia Pugliatti, Carmine Giordano, and Francesco Topputo, ESA-GNC conference, Sopot, Poland, June 2023.</p>

<p>You can download it <a href="https://zenodo.org/record/7962714"> here </a> on Zenodo. What follows is a “description in a nutshell” of the dataset.</p>

<h2 id="why-does-it-exist">Why does it exist?</h2>

<p>Because we wanted to encourage other researchers and IP designers to challenge our results and propose better ones to perform phase-angle estimates from images of the Didymos binary system.</p>

<h2 id="how-was-it-generated">How was it generated?</h2>

<p>In Blender. The main dataset is comprised of two subsets: D1_with_sz_1p00s0 and D1_with_sz_0p78s0</p>

<ul>
  <li>
    <p>D1_with_sz_1p00s0 is made of 5000 image-label pairs with all the rendered data of Didymos using the axis scales of the Didymos Reference Model by ESA (old values before impact).</p>
  </li>
  <li>
    <p>D1_with_sz_0p78s0 is made of 5000 image-label pairs with all the rendered data of Didymos using the updated axis scales from the Didymos Reference Model by JHUAPL (updated values after impact). This directory also contains the processed input-output pairs for the WCOB, NN, and PCE (X_features, Y) and CELM, and CNN (X_images, Y) methods illustrated in the original work. You can either decide to use the same processed data we have used for training, validation, and testing or you can work with the raw data to generate your own tailored dataset.</p>
  </li>
</ul>

<p>There is also auxiliary data that can be used for additional scopes. For example,</p>

<ul>
  <li>
    <p>CoefficientsPCE: with the “PCEFull9.mat” file with all the coefficients of the aPC basis and PCE listed in the paper, saved here as a .mat for convenience</p>
  </li>
  <li>
    <p>TestResults: with the “ResultsAll.mat” file that contains the predicted and true values of phase angle over the test set illustrated in the paper and the “MakePlot.m” script in Matlab. You can use this data to compare your method directly with the results we have obtained in the original paper. The script generates a simple histogram plot and computes the mean, std, Q67, and Q95 values.</p>
  </li>
</ul>

<h2 id="what-can-i-do-with-it">What can I do with it?</h2>

<p>In the original work for which the dataset has been designed, it has been used to perform:</p>

<ul>
  <li>Phase angle regression: to estimate the phase angle from the appearance of the primary asteroid, Didymos, in the images</li>
</ul>

<p>However, we have included all sorts of labels that can be used for many other tasks such as:</p>

<ul>
  <li>
    <p>Centroid regression: to estimate the center of mass in the image plane of Didymos (but also Dimorphos)</p>
  </li>
  <li>
    <p>Object recognition: to perform object recognition and distinguish between Didymos and Dimorphos</p>
  </li>
</ul>

<p>Let us know if you have come up with other uses of the dataset and we will update the list!</p>

<h2 id="how-to-cite-it">How to cite it</h2>

<p>Mattia Pugliatti, Carmine Giordano, &amp; Francesco Topputo. (2023). The image processing of Milani: challenges after DART impact (1.0) [Data set]. Zenodo. https://doi.org/10.5281/zenodo.7962714</p>]]></content><author><name></name></author><category term="regression" /><category term="phase-angle" /><category term="IP-Milani" /><category term="dataset" /><summary type="html"><![CDATA[A description in a nutshell of the IP of Milani dataset]]></summary></entry><entry><title type="html">The “DOORS” dataset</title><link href="https://mattiapugliatti.github.io/blog/2022/doors/" rel="alternate" type="text/html" title="The “DOORS” dataset" /><published>2022-10-14T10:00:00+00:00</published><updated>2022-10-14T10:00:00+00:00</updated><id>https://mattiapugliatti.github.io/blog/2022/doors</id><content type="html" xml:base="https://mattiapugliatti.github.io/blog/2022/doors/"><![CDATA[<h2 id="what-is-doors-">What is “DOORS” ?</h2>

<p>DOORS stands for “Dataset fOr bOuldeRs Segmentation” and is an open-access dataset with single and multiple boulders rendered in Blender over the surface of a small body. You can download it <a href="https://zenodo.org/record/7107409"> here </a> on Zenodo.</p>

<p>Also, you can find a detailed description of the dataset <a href="https://arxiv.org/pdf/2210.16253.pdf"> here </a> on ArXiv.  What follows is a “description in a nutshell” of the dataset.</p>

<h2 id="why-does-it-exist">Why does it exist?</h2>

<p>Because the capability to detect boulders on the surface of small bodies is beneficial for vision-based applications such as hazard detection during critical operations and navigation. This task is challenging due to the wide assortment of irregular shapes, the characteristics of the boulders population, and the rapid variability in the illumination conditions. We believe that the lack of publicly available and labeled datasets for these applications damps the research on this particular area, thus, we have decided to release the internal dataset we have used in “Boulders identification on small bodies under varying illumination conditions” (by Mattia Pugliatti and Francesco Topputo, 3rd Space Imaging Workshop, Georgia, Atlanta, arXiv pre-print, Oct 2022, https://arxiv.org/pdf/2210.16283.pdf) for anyone who wants to play with it.</p>

<h2 id="how-was-it-generated">How was it generated?</h2>

<p>In Blender. The dataset is comprised of two subsets: DS1 and DS2, that are made with slightly different settings.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/DS1.gif-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/DS1.gif-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/DS1.gif-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/DS1.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Samples of DS1
</div>

<p>DS1 is made of 45269 image-label pairs in which a single boulder is represented in the image. The renderings are done in Blender using the following elements:</p>

<ol>
  <li>A single randomly-generated boulder whose Center of Mass (CoM) is positioned in the center of the
Blender reference frame</li>
  <li>A unitary spherical mesh made of 16’258 vertexes and 32’512 faces</li>
  <li>A camera, modeled with a 256 × 256 px size sensor and a FOV of 10 × 10 deg</li>
  <li>A Sun lamp illuminating the scene</li>
</ol>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/DS2.gif-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/DS2.gif-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/DS2.gif-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/DS2.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Samples of DS2
</div>

<p>DS2 is made of 35183 image-label pairs in which multiple boulders are represented in the same image. The renderings are done in Blender using the following elements:</p>

<ol>
  <li>A medium-resolution mesh of the (65803) Didymos asteroid made of 652’032 faces that represents the
surface</li>
  <li>A particle system that scatters randomized populations of boulders from a collection of 30 samples across the surface</li>
  <li>A camera, modeled with a 128 × 128 px size sensor and a FOV of 10 × 10 deg</li>
  <li>A Sun lamp illuminating the scene</li>
</ol>

<h2 id="what-can-i-do-with-it">What can I do with it?</h2>

<p>In the original work for which the dataset has been designed, it has been used to perform:</p>

<ul>
  <li>
    <p>Centroid regression: to estimate the center of mass in the image plane of irregular bodies</p>
  </li>
  <li>
    <p>Boulder segmentation: to segment boulders in images of small body surfaces</p>
  </li>
</ul>

<p>However, we have included all sorts of labels that can be used for many other tasks such as:</p>

<ul>
  <li>
    <p>pose regression: to estimate the camera pose (position and orientation) associated with each image</p>
  </li>
  <li>
    <p>Boulder recognition: to estimate the class of the boulder among the three ones used (Ice, Asteroid, River)</p>
  </li>
  <li>
    <p>Phase angle regression: to estimate the phase angle from the shadows in the images</p>
  </li>
</ul>

<p>Let us know if you have come up with other uses of the dataset and we will update the list!</p>

<h2 id="how-to-cite-it">How to cite it</h2>

<p>The DOORS dataset: 
Mattia Pugliatti, &amp; Francesco Topputo. (2022). DOORS: Dataset fOr bOuldeRs Segmentation (1.0) [Data set]. Zenodo. https://doi.org/10.5281/zenodo.7107409</p>

<p>The statistical characterization of the DOORS dataset: 
“DOORS: Dataset fOr bOuldeRs Segmentation. Statistical properties and Blender setup”, by Mattia Pugliatti and Francesco Topputo, arXiv pre-print, Oct 2022, https://arxiv.org/pdf/2210.16253.pdf</p>

<p>The original paper in which it was first used: 
“Boulders identification on small bodies under varying illumination conditions”, by Mattia Pugliatti and Francesco Topputo, 3rd Space Imaging Workshop, Georgia, Atlanta, arXiv pre-print, Oct 2022, https://arxiv.org/pdf/2210.16283.pdf</p>]]></content><author><name></name></author><category term="segmentation" /><category term="boulders" /><category term="regression" /><category term="dataset" /><summary type="html"><![CDATA[DOORS in a nutshell]]></summary></entry><entry><title type="html">What are asteroids and why you should care about them?</title><link href="https://mattiapugliatti.github.io/blog/2020/what-are-asteroids-and-why-you-should-care-about-them/" rel="alternate" type="text/html" title="What are asteroids and why you should care about them?" /><published>2020-12-14T17:49:30+00:00</published><updated>2020-12-14T17:49:30+00:00</updated><id>https://mattiapugliatti.github.io/blog/2020/what-are-asteroids-and-why-you-should-care-about-them</id><content type="html" xml:base="https://mattiapugliatti.github.io/blog/2020/what-are-asteroids-and-why-you-should-care-about-them/"><![CDATA[]]></content><author><name></name></author></entry></feed>