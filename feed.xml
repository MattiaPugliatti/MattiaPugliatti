<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://mattiapugliatti.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://mattiapugliatti.github.io/" rel="alternate" type="text/html" hreflang="en" /><updated>2025-02-06T00:39:12+00:00</updated><id>https://mattiapugliatti.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
</subtitle><entry><title type="html">My Ph.D. defense</title><link href="https://mattiapugliatti.github.io/blog/2023/PhDdefense/" rel="alternate" type="text/html" title="My Ph.D. defense" /><published>2023-11-27T10:00:00+00:00</published><updated>2023-11-27T10:00:00+00:00</updated><id>https://mattiapugliatti.github.io/blog/2023/PhDdefense</id><content type="html" xml:base="https://mattiapugliatti.github.io/blog/2023/PhDdefense/"><![CDATA[<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0 text-center">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/PhDtheme-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/PhDtheme-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/PhDtheme-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/PhDtheme.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Small bodies and neural networks
</div>

<h2 id="intro">Intro</h2>

<p>On the 27th of November 2023, I successfully defended my Ph.D. thesis with the title “Data-Driven Image Processing for Enhanced Vision-Based Applications Around Small Bodies With Machine Learning”.</p>

<p>If you would have been interested in attending but you missed it, don’t worry! In this post, I share all the publicly available material about the defense and the manuscript, with the hope that it could be useful for someone else. Enjoy!</p>

<h2 id="abstract">Abstract</h2>

<p>The space sector is undergoing rapid growth, especially in near-Earth orbits, promising unprecedented benefits through integrated space-based services. At the same time, CubeSats are reshaping deep space by diversifying scientific objectives and complementing traditional missions. Profiting from this favorable environment, a surge in deep-space missions dedicated to the exploration and exploitation of the Solar System is on the horizon. Within this context, small celestial bodies, such as asteroids and comets, emerge as intriguing targets due to their abundance, proximity to Earth’s orbit, ancient origins, importance for planetary defense, potential for resource utilization, and the quest for extraterrestrial life. However, the operation of a large fleet of spacecraft exploring these deep space bodies poses critical challenges when approached with the current ground-based paradigm. Driven by the need for real-time decision-making and cost-effective solutions, technological advancements are gearing towards autonomous spacecraft operations. Within this context, artificial intelligence enhancements on computer vision tasks are posed to enrich perception and spatial comprehension of the surrounding environment, enabling intelligent spacecraft to operate effortlessly and autonomously. Image segmentation and visual-based navigation, in particular, are investigated in this manuscript using neural networks and machine learning approaches. Data-driven image processing options are also assessed for the future CubeSat mission Milani, which will visit the Didymos binary system. Milani’s semi-autonomous vision-based capabilities pave the way for adopting data-driven algorithms in deep space. Assessing the performance of these techniques is as important as highlighting their drawbacks and the challenges associated with their development, primarily related to the availability of high-quality training data. The integration of artificial intelligence and autonomous capabilities holds the potential to revolutionize our engagement with minor bodies, shaping the future of space exploration.</p>

<h2 id="useful-links">Useful links</h2>

<ul>
  <li>
    <p>Defense video: <a href="https://drive.google.com/file/d/1LqbR87qLxVOnVJkaNRnpOtmr22fWC5Vj/view?usp=sharing"> here </a></p>
  </li>
  <li>
    <p>Defense slides: <a href="https://drive.google.com/file/d/1mARpjKxvLETxslgYHqYp5j9VPgFi8kA5/view?usp=sharing"> PDF-slides </a></p>
  </li>
  <li>
    <p>Thesis manuscript: <a href="https://hdl.handle.net/10589/213552"> POLItesi </a></p>
  </li>
</ul>

<h2 id="acknowledgments">Acknowledgments</h2>

<p>Let me thank my supervisor, Prof. Francesco Topputo, the external reviewers (Prof. Jay McMahon and Dr.Svenja Woicke), the PhD defence committee (Prof. Massimiliano Vasile, Dr. Svenja Woicke, and Prof. Fabio Ferrari), and the European Commission for having funded this research as part of the <a href="https://cordis.europa.eu/project/id/813644"> Stardust-R </a>Innovative Training Network.</p>]]></content><author><name></name></author><category term="PhD" /><category term="data-driven" /><category term="regression" /><category term="segmentation" /><category term="dataset" /><summary type="html"><![CDATA[Brief overview, recording, and presentation of my Ph.D. defense at Politecnico di Milano]]></summary></entry><entry><title type="html">The “Milani IP” Dataset</title><link href="https://mattiapugliatti.github.io/blog/2023/milani/" rel="alternate" type="text/html" title="The “Milani IP” Dataset" /><published>2023-05-29T10:00:00+00:00</published><updated>2023-05-29T10:00:00+00:00</updated><id>https://mattiapugliatti.github.io/blog/2023/milani</id><content type="html" xml:base="https://mattiapugliatti.github.io/blog/2023/milani/"><![CDATA[<h2 id="what-is-the-milani-ip-dataset">What is the “Milani IP” Dataset?</h2>

<p>This dataset contains data used in the work “The image processing of Milani challenges after DART impact”, by Mattia Pugliatti, Carmine Giordano, and Francesco Topputo, ESA-GNC conference, Sopot, Poland, June 2023.</p>

<p>You can download it <a href="https://zenodo.org/record/7962714"> here </a> on Zenodo. What follows is a “description in a nutshell” of the dataset.</p>

<h2 id="why-does-it-exist">Why does it exist?</h2>

<p>Because we wanted to encourage other researchers and IP designers to challenge our results and propose better ones to perform phase-angle estimates from images of the Didymos binary system.</p>

<h2 id="how-was-it-generated">How was it generated?</h2>

<p>In Blender. The main dataset is comprised of two subsets: D1_with_sz_1p00s0 and D1_with_sz_0p78s0</p>

<ul>
  <li>
    <p>D1_with_sz_1p00s0 is made of 5000 image-label pairs with all the rendered data of Didymos using the axis scales of the Didymos Reference Model by ESA (old values before impact).</p>
  </li>
  <li>
    <p>D1_with_sz_0p78s0 is made of 5000 image-label pairs with all the rendered data of Didymos using the updated axis scales from the Didymos Reference Model by JHUAPL (updated values after impact). This directory also contains the processed input-output pairs for the WCOB, NN, and PCE (X_features, Y) and CELM, and CNN (X_images, Y) methods illustrated in the original work. You can either decide to use the same processed data we have used for training, validation, and testing or you can work with the raw data to generate your own tailored dataset.</p>
  </li>
</ul>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0 text-center">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/MilaniIP.gif-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/MilaniIP.gif-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/MilaniIP.gif-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/MilaniIP.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Samples of D1_with_sz_1p00s0
</div>

<p>There is also auxiliary data that can be used for additional scopes. For example,</p>

<ul>
  <li>
    <p>CoefficientsPCE: with the “PCEFull9.mat” file with all the coefficients of the aPC basis and PCE listed in the paper, saved here as a .mat for convenience</p>
  </li>
  <li>
    <p>TestResults: with the “ResultsAll.mat” file that contains the predicted and true values of phase angle over the test set illustrated in the paper and the “MakePlot.m” script in Matlab. You can use this data to compare your method directly with the results we have obtained in the original paper. The script generates a simple histogram plot and computes the mean, std, Q67, and Q95 values.</p>
  </li>
</ul>

<h2 id="what-can-i-do-with-it">What can I do with it?</h2>

<p>In the original work for which the dataset has been designed, it has been used to perform:</p>

<ul>
  <li>Phase angle regression: to estimate the phase angle from the appearance of the primary asteroid, Didymos, in the images</li>
</ul>

<p>However, we have included all sorts of labels that can be used for many other tasks such as:</p>

<ul>
  <li>
    <p>Centroid regression: to estimate the center of mass in the image plane of Didymos (but also Dimorphos)</p>
  </li>
  <li>
    <p>Object recognition: to perform object recognition and distinguish between Didymos and Dimorphos</p>
  </li>
</ul>

<p>Let us know if you have come up with other uses of the dataset and we will update the list!</p>

<h2 id="how-to-cite-it">How to cite it</h2>

<p>Mattia Pugliatti, Carmine Giordano, &amp; Francesco Topputo. (2023). The image processing of Milani: challenges after DART impact (1.0) [Data set]. Zenodo. https://doi.org/10.5281/zenodo.7962714</p>]]></content><author><name></name></author><category term="regression" /><category term="phase-angle" /><category term="IP-Milani" /><category term="dataset" /><summary type="html"><![CDATA[A description in a nutshell of the IP of Milani dataset]]></summary></entry><entry><title type="html">The “DOORS” dataset</title><link href="https://mattiapugliatti.github.io/blog/2022/doors/" rel="alternate" type="text/html" title="The “DOORS” dataset" /><published>2022-10-14T10:00:00+00:00</published><updated>2022-10-14T10:00:00+00:00</updated><id>https://mattiapugliatti.github.io/blog/2022/doors</id><content type="html" xml:base="https://mattiapugliatti.github.io/blog/2022/doors/"><![CDATA[<h2 id="what-is-doors-">What is “DOORS” ?</h2>

<p>DOORS stands for “Dataset fOr bOuldeRs Segmentation” and is an open-access dataset with single and multiple boulders rendered in Blender over the surface of a small body. You can download it <a href="https://zenodo.org/record/7107409"> here </a> on Zenodo.</p>

<p>Also, you can find a detailed description of the dataset <a href="https://arxiv.org/pdf/2210.16253.pdf"> here </a> on ArXiv.  What follows is a “description in a nutshell” of the dataset.</p>

<h2 id="why-does-it-exist">Why does it exist?</h2>

<p>Because the capability to detect boulders on the surface of small bodies is beneficial for vision-based applications such as hazard detection during critical operations and navigation. This task is challenging due to the wide assortment of irregular shapes, the characteristics of the boulders population, and the rapid variability in the illumination conditions. We believe that the lack of publicly available and labeled datasets for these applications damps the research on this particular area, thus, we have decided to release the internal dataset we have used in “Boulders identification on small bodies under varying illumination conditions” (by Mattia Pugliatti and Francesco Topputo, 3rd Space Imaging Workshop, Georgia, Atlanta, arXiv pre-print, Oct 2022, https://arxiv.org/pdf/2210.16283.pdf) for anyone who wants to play with it.</p>

<h2 id="how-was-it-generated">How was it generated?</h2>

<p>In Blender. The dataset is comprised of two subsets: DS1 and DS2, that are made with slightly different settings.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0 text-center">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/DS1.gif-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/DS1.gif-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/DS1.gif-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/DS1.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Samples of DS1
</div>

<p>DS1 is made of 45269 image-label pairs in which a single boulder is represented in the image. The renderings are done in Blender using the following elements:</p>

<ol>
  <li>A single randomly-generated boulder whose Center of Mass (CoM) is positioned in the center of the
Blender reference frame</li>
  <li>A unitary spherical mesh made of 16’258 vertexes and 32’512 faces</li>
  <li>A camera, modeled with a 256 × 256 px size sensor and a FOV of 10 × 10 deg</li>
  <li>A Sun lamp illuminating the scene</li>
</ol>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0 text-center">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/DS2.gif-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/DS2.gif-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/DS2.gif-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/DS2.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Samples of DS2
</div>

<p>DS2 is made of 35183 image-label pairs in which multiple boulders are represented in the same image. The renderings are done in Blender using the following elements:</p>

<ol>
  <li>A medium-resolution mesh of the (65803) Didymos asteroid made of 652’032 faces that represents the
surface</li>
  <li>A particle system that scatters randomized populations of boulders from a collection of 30 samples across the surface</li>
  <li>A camera, modeled with a 128 × 128 px size sensor and a FOV of 10 × 10 deg</li>
  <li>A Sun lamp illuminating the scene</li>
</ol>

<h2 id="what-can-i-do-with-it">What can I do with it?</h2>

<p>In the original work for which the dataset has been designed, it has been used to perform:</p>

<ul>
  <li>
    <p>Centroid regression: to estimate the center of mass in the image plane of irregular bodies</p>
  </li>
  <li>
    <p>Boulder segmentation: to segment boulders in images of small body surfaces</p>
  </li>
</ul>

<p>However, we have included all sorts of labels that can be used for many other tasks such as:</p>

<ul>
  <li>
    <p>pose regression: to estimate the camera pose (position and orientation) associated with each image</p>
  </li>
  <li>
    <p>Boulder recognition: to estimate the class of the boulder among the three ones used (Ice, Asteroid, River)</p>
  </li>
  <li>
    <p>Phase angle regression: to estimate the phase angle from the shadows in the images</p>
  </li>
</ul>

<p>Let us know if you have come up with other uses of the dataset and we will update the list!</p>

<h2 id="how-to-cite-it">How to cite it</h2>

<p>The DOORS dataset: 
Mattia Pugliatti, &amp; Francesco Topputo. (2022). DOORS: Dataset fOr bOuldeRs Segmentation (1.0) [Data set]. Zenodo. https://doi.org/10.5281/zenodo.7107409</p>

<p>The statistical characterization of the DOORS dataset: 
“DOORS: Dataset fOr bOuldeRs Segmentation. Statistical properties and Blender setup”, by Mattia Pugliatti and Francesco Topputo, arXiv pre-print, Oct 2022, https://arxiv.org/pdf/2210.16253.pdf</p>

<p>The original paper in which it was first used: 
“Boulders identification on small bodies under varying illumination conditions”, by Mattia Pugliatti and Francesco Topputo, 3rd Space Imaging Workshop, Georgia, Atlanta, arXiv pre-print, Oct 2022, https://arxiv.org/pdf/2210.16283.pdf</p>]]></content><author><name></name></author><category term="segmentation" /><category term="boulders" /><category term="regression" /><category term="dataset" /><summary type="html"><![CDATA[DOORS in a nutshell]]></summary></entry><entry><title type="html">What are asteroids and why you should care about them?</title><link href="https://mattiapugliatti.github.io/blog/2020/what-are-asteroids-and-why-you-should-care-about-them/" rel="alternate" type="text/html" title="What are asteroids and why you should care about them?" /><published>2020-12-14T17:49:30+00:00</published><updated>2020-12-14T17:49:30+00:00</updated><id>https://mattiapugliatti.github.io/blog/2020/what-are-asteroids-and-why-you-should-care-about-them</id><content type="html" xml:base="https://mattiapugliatti.github.io/blog/2020/what-are-asteroids-and-why-you-should-care-about-them/"><![CDATA[]]></content><author><name></name></author></entry></feed>